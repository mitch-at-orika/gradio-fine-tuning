{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e976a1b-9954-4153-8ece-bf243eb8b674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7835d94-1494-42cb-97f1-8cf31fbcbf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install fastchat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8c6720c-5ab8-44c5-b5cd-5f7cc055f84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "from fastchat.conversation import Conversation, SeparatorStyle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d57f8665-7a68-4284-8aca-3c1201c6b0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_nb_dir = os.getcwd() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79f595db-9b99-41a0-9712-f2c708bca27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54c87839-326e-40fb-8fac-2e22324e15bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/c/users/MitchellBaskerville/code/gradio-fine-tuning/notebooks/../datasets/'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files = []\n",
    "for file in glob(this_nb_dir+\"/../datasets/\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964c8721-da51-419c-858a-b6faefeb3e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_csv = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254f5261-2e67-4b01-8e93-1163ac22cee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_raw_qa_pairs = pd.concat(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c87fe5-ddc9-4547-b35b-8253c46194b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from fastchat.conversation import Conversation, SeparatorStyle\n",
    "\n",
    "def convert_series_to_jsonl(series, output_json_filepath):\n",
    "    with open(output_json_filepath, 'w') as jsonl_file:\n",
    "        for instruction, response in series.items():\n",
    "            conv = Conversation(\n",
    "                name=\"alpaca\",\n",
    "                system_message=\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\",\n",
    "                roles=(\"### Instruction\", \"### Response\"),\n",
    "                sep_style=SeparatorStyle.ADD_COLON_TWO,\n",
    "                sep=\"\\n\\n\",\n",
    "                sep2=\"</s>\"\n",
    "            )\n",
    "            conv.append_message(\"### Instruction\", instruction)\n",
    "            conv.append_message(\"### Response\", response)\n",
    "            prompt = conv.get_prompt()\n",
    "            json_line = json.dumps({\"prompt\": prompt})\n",
    "            jsonl_file.write(json_line + '\\n')\n",
    "\n",
    "# Usage example:\n",
    "# Assuming you have a pandas Series with 'instruction' as the index name and responses as the Series values.\n",
    "# series = pd.Series({\"Tell me a joke.\": \"Why don't scientists trust atoms? Because they make up everything!\",\n",
    "#                     \"What is the capital of France?\": \"The capital of France is Paris.\"},\n",
    "#                    name='response')\n",
    "# series.index.name = 'instruction'\n",
    "\n",
    "# output_json_filepath = 'output.jsonl'\n",
    "# convert_series_to_jsonl(series, output_json_filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c01d1c6-7156-426c-8f22-62e422db7d10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1244faf6-b5af-468f-96c3-353e29f1f248",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "<example_config_axolotl_llama3_qlora>\n",
    "base_model: meta-llama/Meta-Llama-3-8B\n",
    "model_type: AutoModelForCausalLM\n",
    "tokenizer_type: AutoTokenizer\n",
    "\n",
    "load_in_8bit: false\n",
    "load_in_4bit: true\n",
    "strict: false\n",
    "\n",
    "datasets:\n",
    "  - path: _synth_data/gradio_QA_data.jsonl\n",
    "    type: sharegpt\n",
    "    conversation: alpaca\n",
    "dataset_prepared_path:\n",
    "val_set_size: 0\n",
    "output_dir: ./outputs/qlora-out\n",
    "\n",
    "adapter: qlora\n",
    "lora_model_dir:\n",
    "\n",
    "sequence_len: 4096\n",
    "sample_packing: true\n",
    "pad_to_sequence_len: true\n",
    "\n",
    "lora_r: 32\n",
    "lora_alpha: 16\n",
    "lora_dropout: 0.05\n",
    "lora_target_modules:\n",
    "lora_target_linear: true\n",
    "lora_fan_in_fan_out:\n",
    "\n",
    "wandb_project:\n",
    "wandb_entity:\n",
    "wandb_watch:\n",
    "wandb_name:\n",
    "wandb_log_model:\n",
    "\n",
    "gradient_accumulation_steps: 4\n",
    "micro_batch_size: 2\n",
    "num_epochs: 4\n",
    "optimizer: paged_adamw_32bit\n",
    "lr_scheduler: cosine\n",
    "learning_rate: 0.0002\n",
    "\n",
    "train_on_inputs: false\n",
    "group_by_length: false\n",
    "bf16: auto\n",
    "fp16:\n",
    "tf32: false\n",
    "\n",
    "gradient_checkpointing: true\n",
    "early_stopping_patience:\n",
    "resume_from_checkpoint:\n",
    "local_rank:\n",
    "logging_steps: 1\n",
    "xformers_attention:\n",
    "flash_attention: true\n",
    "\n",
    "warmup_steps: 10\n",
    "evals_per_epoch: 4\n",
    "eval_table_size:\n",
    "saves_per_epoch: 1\n",
    "debug:\n",
    "deepspeed:\n",
    "weight_decay: 0.0\n",
    "fsdp:\n",
    "fsdp_config:\n",
    "special_tokens:\n",
    "  pad_token: \"<|end_of_text|>\"\n",
    "</example_config_axolotl_llama3_qlora>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56baa78-5b4e-4718-862e-ec4368c67b38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
