{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b91d884a-7789-4286-b8f8-f5be33ec1983",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2748a681-2f0e-447d-a1fb-933382dfda61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from anthropic import Anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b086321-fb2b-481a-a782-4de9e0e4eb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "27b2ce5d-1369-47f9-b5ba-4f6f67bcb94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55a111b3-6f48-4ea9-9d7b-2335521dcac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a63503f5-f67a-4578-a62a-06cc9ec5e5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fc9f3b81-3921-4327-8a93-461c3d09d4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9071fde9-aec2-4b97-8ae1-b69c574319f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ['ANTHROPIC_API_KEY'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8430e3cb-3b75-46d2-9701-1ec8892fb06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = Anthropic(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.environ.get(\"ANTHROPIC_API_KEY\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ab1807b-9795-43c9-9228-10b6e5388383",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_demos = pd.read_parquet('../data/latest-demos/all_demo_python.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dfb5719-f3b1-49d3-b782-10557bba63bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_demo = all_demos.iloc[62]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43c3eed4-3595-4a69-9ed6-b7a5719e70fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "its = this_demo['input type(s)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02f95ddc-a63c-4e94-88d1-6dee87b17508",
   "metadata": {},
   "outputs": [],
   "source": [
    "ots = this_demo['output type(s)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7d02cabe-c1a9-4e3f-83b9-295e2d123b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt template\n",
    "prompt_template = \"\"\"\n",
    "You will be acting as a dataset generator to help develop a fine-tuning dataset for training an AI coding assistant for the Gradio Python framework. \n",
    "You will return a response as though you are writting the initial prompt that generated the SOLUTION_EXAMPLE\n",
    "\n",
    "Here is an example solution in Python code:\n",
    "\n",
    "<solution_example>\n",
    "{{SOLUTION_EXAMPLE}}\n",
    "</solution_example>\n",
    "\n",
    "And here is some information about the solution:\n",
    "\n",
    "<solution_information>\n",
    "{{SOLUTION_INFORMATION}}\n",
    "</solution_information>\n",
    "\n",
    "Imagine that you were the human who first thought of the idea to develop that Gradio solution. Firstly give a brief overview of the non gradio components of the code amd summarize or generalize \n",
    "them such as \"I have ... and with my current model/code I can produce an output ...\" then go into more detail on what you would like gradio to do, what features Gradio you want to use which components need to be interactice etc etc.\n",
    "\n",
    "For example, the prompt might look something like:\n",
    "<prompt>\n",
    "I have a machine learning model that can take in text and classify the sentiment as positive or negative. With my current code, I can run the model and get the predicted sentiment label as output. \n",
    "\n",
    "I would like to create a simple Gradio web interface for my model with the following:\n",
    "- A text input box for the user to enter the text to classify \n",
    "- A submit button to run the classification\n",
    "- Display the output sentiment label after submitting\n",
    "- A clear button to reset the interface \n",
    "</prompt>\n",
    "\n",
    "Please return only the prompt that could have generated the given solution.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "71d8eba0-daca-48b8-a3b7-7f53e65ca271",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b840acd7-82ca-475b-8432-7a2621054e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 67/67 [14:41<00:00, 13.16s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(all_demos))):\n",
    "    this_demo = all_demos.iloc[i]\n",
    "    prompt = prompt_template.replace(\"{{SOLUTION_EXAMPLE}}\", f\"```python\\n{this_demo.python_str}\\n```\").replace(\"{{SOLUTION_INFORMATION}}\",f'this solution has been categorised as {this_demo.level_0} and contains {its} input types and the solution outputs {ots}  types ')\n",
    "    message = client.messages.create(\n",
    "        model=\"claude-3-opus-20240229\",\n",
    "        max_tokens=1000,\n",
    "        temperature=0.1,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": prompt\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    # Append the response to the list\n",
    "    responses.append(message.content[0].text)\n",
    "    counter_incase_crash+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b1d84c75-c1ba-4365-a5ba-aa2710497067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the responses\n",
    "responses_clean=[]\n",
    "for response in responses:\n",
    "    root = ET.fromstring(f\"<root>{response}</root>\")\n",
    "    result_element = root.find('prompt')\n",
    "    result_content = result_element.text\n",
    "    responses_clean.append(result_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0b91ddce-3324-4a86-86ad-cfde6bff5b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df = pd.Series(responses_clean).rename('question')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "21c78c91-bcbb-4cbd-b018-aa34b11450bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "as_answers = all_demos.python_str.apply(lambda x: f'here is the gradio solution for your use case: ```python\\n{x}\\n```').rename('answer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "40c2b4e9-c024-467d-8244-dcb8957a1b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_out = pd.concat([responses_df,as_answers],axis=1).astype(str)\n",
    "qa_out.to_parquet(os.getcwd() + f'/../datasets/raw/opus_demos_qas.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6484c645-e056-4a15-b638-e92c70eb4013",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_json_filepath = os.getcwd() + f'/../datasets/qa_pairs/opus_demos_qas.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "75816877-bfb6-4baf-a4b0-866d94771c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_out.to_json(output_json_filepath,orient='records',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb77b639-8616-4162-9426-4f2814e2c819",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
