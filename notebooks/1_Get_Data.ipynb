{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data\n",
    "\n",
    "This notebook fetches the latest data for Gradio fine-tuning from various sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib.parse import urljoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# headers = {\n",
    "#     \"Authorization\": f\"Bearer {'your_token_here'}\"\n",
    "# }\n",
    "# i got rate limited so had to go get a auth token at https://github.com/settings/tokens but you should be ok to run once without this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get latest gradio repo python code\n",
    "for this I am utilising this [github2file](https://github.com/cognitivecomputations/github2file) repo from the inspirational ehartford "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(this_dir+\"/../../github2file/\") # assumed you cloned that repo next to this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://github.com/gradio-app/gradio/archive/refs/heads/master.zip\n",
      "Combined Python source code saved to gradio_python.txt\n"
     ]
    }
   ],
   "source": [
    "!python github2file.py https://github.com/gradio-app/gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../gradio-fine-tuning/data/latest-repo/gradio_repo_one_file.txt'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.copy(\"gradio_python.txt\", this_dir + \"/../data/latest-repo/gradio_repo_one_file.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get latest gradio repo docs / guides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(this_dir+\"/../data/latest-docs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base URL for the repository and the sub-directory\n",
    "base_url = 'https://github.com/gradio-app/gradio/'\n",
    "sub_directory = 'main/guides/'\n",
    "\n",
    "# GitHub API base URL for fetching repository contents\n",
    "api_base_url = 'https://api.github.com/repos/gradio-app/gradio/contents/guides'\n",
    "\n",
    "# Directory to save downloaded files\n",
    "save_directory = './'\n",
    "\n",
    "# Create the save directory if it doesn't exist\n",
    "if not os.path.exists(save_directory):\n",
    "    os.makedirs(save_directory)\n",
    "\n",
    "def download_file(file_url, save_path):\n",
    "    response = requests.get(file_url)\n",
    "    if response.status_code == 200:\n",
    "        with open(save_path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"Downloaded: {save_path}\")\n",
    "    else:\n",
    "        print(f\"Failed to download {file_url}\")\n",
    "\n",
    "def get_files_from_github(api_url,headers):\n",
    "    if headers = None:\n",
    "        response = requests.get(api_url)\n",
    "    else:\n",
    "        response = requests.get(api_url,headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Failed to fetch repository contents: {response.status_code}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_directory(api_url, local_dir,headers=None):\n",
    "    contents = get_files_from_github(api_url,headers)\n",
    "    \n",
    "    for item in contents:\n",
    "        if (item['type'] == 'dir') & (\"cn\" not in item['name']) & (\"assets\" not in item['name']): #ignore the chinese version - gonna finetune in english\n",
    "            # Create a corresponding local directory\n",
    "            new_local_dir = os.path.join(local_dir, item['name'])\n",
    "            if not os.path.exists(new_local_dir):\n",
    "                os.makedirs(new_local_dir)\n",
    "            # Recursively process the sub-directory\n",
    "            process_directory(item['url'], new_local_dir,headers)\n",
    "        elif item['type'] == 'file' and item['name'].endswith('.md'):\n",
    "            # Download the file\n",
    "            download_file(item['download_url'], os.path.join(local_dir, item['name']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: ./01_getting-started/01_quickstart.md\n",
      "Downloaded: ./01_getting-started/02_key-features.md\n",
      "Downloaded: ./02_building-interfaces/00_the-interface-class.md\n",
      "Downloaded: ./02_building-interfaces/01_more-on-examples.md\n",
      "Downloaded: ./02_building-interfaces/02_flagging.md\n",
      "Downloaded: ./02_building-interfaces/03_interface-state.md\n",
      "Downloaded: ./02_building-interfaces/04_reactive-interfaces.md\n",
      "Downloaded: ./02_building-interfaces/05_four-kinds-of-interfaces.md\n",
      "Downloaded: ./03_additional-features/01_queuing.md\n",
      "Downloaded: ./03_additional-features/02_streaming-outputs.md\n",
      "Downloaded: ./03_additional-features/03_alerts.md\n",
      "Downloaded: ./03_additional-features/04_styling.md\n",
      "Downloaded: ./03_additional-features/05_progress_bars.md\n",
      "Downloaded: ./03_additional-features/06_batch-functions.md\n",
      "Downloaded: ./03_additional-features/07_sharing-your-app.md\n",
      "Downloaded: ./04_building-with-blocks/01_blocks-and-event-listeners.md\n",
      "Downloaded: ./04_building-with-blocks/02_controlling-layout.md\n",
      "Downloaded: ./04_building-with-blocks/03_state-in-blocks.md\n",
      "Downloaded: ./04_building-with-blocks/04_dynamic-apps-with-render-decorator.md\n",
      "Downloaded: ./04_building-with-blocks/05_custom-CSS-and-JS.md\n",
      "Downloaded: ./04_building-with-blocks/06_using-blocks-like-functions.md\n",
      "Downloaded: ./05_chatbots/01_creating-a-chatbot-fast.md\n",
      "Downloaded: ./05_chatbots/02_creating-a-custom-chatbot-with-blocks.md\n",
      "Downloaded: ./05_chatbots/03_creating-a-discord-bot-from-a-gradio-app.md\n",
      "Downloaded: ./06_custom-components/01_custom-components-in-five-minutes.md\n",
      "Downloaded: ./06_custom-components/02_key-component-concepts.md\n",
      "Downloaded: ./06_custom-components/03_configuration.md\n",
      "Downloaded: ./06_custom-components/04_backend.md\n",
      "Downloaded: ./06_custom-components/05_frontend.md\n",
      "Downloaded: ./06_custom-components/06_frequently-asked-questions.md\n",
      "Downloaded: ./06_custom-components/07_pdf-component-example.md\n",
      "Downloaded: ./06_custom-components/08_multimodal-chatbot-part1.md\n",
      "Downloaded: ./06_custom-components/09_documenting-custom-components.md\n",
      "Downloaded: ./07_tabular-data-science-and-plots/01_connecting-to-a-database.md\n",
      "Downloaded: ./07_tabular-data-science-and-plots/creating-a-dashboard-from-bigquery-data.md\n",
      "Downloaded: ./07_tabular-data-science-and-plots/creating-a-dashboard-from-supabase-data.md\n",
      "Downloaded: ./07_tabular-data-science-and-plots/creating-a-realtime-dashboard-from-google-sheets.md\n",
      "Downloaded: ./07_tabular-data-science-and-plots/plot-component-for-maps.md\n",
      "Downloaded: ./07_tabular-data-science-and-plots/styling-the-gradio-dataframe.md\n",
      "Downloaded: ./07_tabular-data-science-and-plots/using-gradio-for-tabular-workflows.md\n",
      "Downloaded: ./08_gradio-clients-and-lite/01_getting-started-with-the-python-client.md\n",
      "Downloaded: ./08_gradio-clients-and-lite/02_getting-started-with-the-js-client.md\n",
      "Downloaded: ./08_gradio-clients-and-lite/03_fastapi-app-with-the-gradio-client.md\n",
      "Downloaded: ./08_gradio-clients-and-lite/04_gradio-and-llm-agents.md\n",
      "Downloaded: ./08_gradio-clients-and-lite/05_gradio-lite.md\n",
      "Downloaded: ./08_gradio-clients-and-lite/06_gradio-lite-and-transformers-js.md\n",
      "Downloaded: ./09_other-tutorials/01_using-hugging-face-integrations.md\n",
      "Downloaded: ./09_other-tutorials/Gradio-and-Comet.md\n",
      "Downloaded: ./09_other-tutorials/Gradio-and-ONNX-on-Hugging-Face.md\n",
      "Downloaded: ./09_other-tutorials/Gradio-and-Wandb-Integration.md\n",
      "Downloaded: ./09_other-tutorials/create-your-own-friends-with-a-gan.md\n",
      "Downloaded: ./09_other-tutorials/deploying-gradio-with-docker.md\n",
      "Downloaded: ./09_other-tutorials/developing-faster-with-reload-mode.md\n",
      "Downloaded: ./09_other-tutorials/how-to-use-3D-model-component.md\n",
      "Downloaded: ./09_other-tutorials/image-classification-in-pytorch.md\n",
      "Downloaded: ./09_other-tutorials/image-classification-in-tensorflow.md\n",
      "Downloaded: ./09_other-tutorials/image-classification-with-vision-transformers.md\n",
      "Downloaded: ./09_other-tutorials/installing-gradio-in-a-virtual-environment.md\n",
      "Downloaded: ./09_other-tutorials/named-entity-recognition.md\n",
      "Downloaded: ./09_other-tutorials/real-time-speech-recognition.md\n",
      "Downloaded: ./09_other-tutorials/running-background-tasks.md\n",
      "Downloaded: ./09_other-tutorials/running-gradio-on-your-web-server-with-nginx.md\n",
      "Downloaded: ./09_other-tutorials/setting-up-a-demo-for-maximum-performance.md\n",
      "Downloaded: ./09_other-tutorials/theming-guide.md\n",
      "Downloaded: ./09_other-tutorials/using-flagging.md\n",
      "Downloaded: ./09_other-tutorials/wrapping-layouts.md\n",
      "Downloaded: ./CONTRIBUTING.md\n"
     ]
    }
   ],
   "source": [
    "process_directory(api_base_url, save_directory,headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat and Existing User Queries\n",
    "### TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\"https://raw.githubusercontent.com/gradio-app/awesome-demos/main/README.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readme_content = response.text\n",
    "\n",
    "# Convert markdown to HTML\n",
    "html_content = markdown(readme_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert markdown table to pandas DataFrame\n",
    "def markdown_table_to_dataframe(table):\n",
    "    rows = table.strip().split('\\n')\n",
    "    header = rows[0]\n",
    "    columns = [col.strip() for col in header.split('|') if col.strip()]\n",
    "    data = []\n",
    "    for row in rows[2:]:  # Skip the header and separator rows\n",
    "        values = [val.strip() for val in row.split('|') if val.strip()]\n",
    "        if values:\n",
    "            data.append(values)\n",
    "    return pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_links = {}\n",
    "for section in readme_content.split('##')[1:]:\n",
    "        \n",
    "    \n",
    "    title, table = section.split('|',1)\n",
    "    title=title.strip()\n",
    "    table=\"|\"+table\n",
    "    \n",
    "    \n",
    "    all_links[title] = markdown_table_to_dataframe(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_demo_links = pd.concat(all_links).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_regex=re.compile(r'\\[.*?\\]\\((.*?)\\)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_link(link_row):\n",
    "    raw_link = (link_regex.search(link_row['Demo name (link to demo)'])[1]+\"/raw/main/app.py\")\n",
    "    \n",
    "    try:\n",
    "        return requests.get(raw_link).text\n",
    "    except:\n",
    "        print(raw_link)\n",
    "        return 'FAILED ' + raw_link \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_demo_links['python_str'] = all_demo_links.apply(lambda x: get_link(x),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(Markdown(f\"```python\\n{all_demo_links.iloc[10]['python_str']}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capture static status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_row = all_demo_links.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_status(link_row):\n",
    "    response = requests.get(link_regex.search(link_row['status badge'])[1])\n",
    "    \n",
    "    if \"demo status: up\" in str(response.content):\n",
    "        return 'up'\n",
    "    else:\n",
    "        return 'drama'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_demo_links['static_status'] = all_demo_links.apply(lambda x: get_status(x),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_demo_links.to_parquet( this_dir + \"/../data/latest-demos/all_demo_python.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "import gradio as gr\n",
       "import numpy as np\n",
       "import matplotlib.pyplot as plt\n",
       "import gpytorch\n",
       "import torch\n",
       "import sys\n",
       "\n",
       "import gpytorch\n",
       "\n",
       "# We will use the simplest form of GP model, exact inference\n",
       "class ExactGPModel(gpytorch.models.ExactGP):\n",
       "    def __init__(self, train_x, train_y, likelihood):\n",
       "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
       "        self.mean_module = gpytorch.means.ConstantMean()\n",
       "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
       "\n",
       "    def forward(self, x):\n",
       "        mean_x = self.mean_module(x)\n",
       "        covar_x = self.covar_module(x)\n",
       "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
       "\n",
       "def get_model(x, y, hyperparameters):\n",
       "    likelihood = gpytorch.likelihoods.GaussianLikelihood(noise_constraint=gpytorch.constraints.GreaterThan(1.e-9))\n",
       "    model = ExactGPModel(x, y, likelihood)\n",
       "    model.likelihood.noise = torch.ones_like(model.likelihood.noise) * hyperparameters[\"noise\"]\n",
       "    model.covar_module.outputscale = torch.ones_like(model.covar_module.outputscale) * hyperparameters[\"outputscale\"]\n",
       "    model.covar_module.base_kernel.lengthscale = torch.ones_like(model.covar_module.base_kernel.lengthscale) * \\\n",
       "                                                 hyperparameters[\"lengthscale\"]\n",
       "    return model, likelihood\n",
       "\n",
       "\n",
       "\n",
       "excuse = \"Please only specify numbers, x values should be in [0,1] and y values in [-1,1].\"\n",
       "excuse_max_examples = \"This model is trained to work with up to 4 input points.\"\n",
       "hyperparameters = {'noise': 1e-4, 'outputscale': 1., 'lengthscale': .1, 'fast_computations': (False,False,False)}\n",
       "\n",
       "\n",
       "conf = .5\n",
       "\n",
       "def mean_and_bounds_for_gp(x,y,test_xs):\n",
       "    gp_model, likelihood = get_model(x,y,hyperparameters)\n",
       "    gp_model.eval()\n",
       "    l = likelihood(gp_model(test_xs))\n",
       "    means = l.mean.squeeze()\n",
       "    varis = torch.diagonal(l.covariance_matrix.squeeze())\n",
       "    stds = varis.sqrt()\n",
       "    return means, means-stds, means+stds\n",
       "\n",
       "\n",
       "def mean_and_bounds_for_pnf(x,y,test_xs, choice):\n",
       "    sys.path.append('prior-fitting/')\n",
       "    model = torch.load(f'onefeature_gp_ls.1_pnf_{choice}.pt')\n",
       "\n",
       "    logits = model((torch.cat([x,test_xs],0).unsqueeze(1),y.unsqueeze(1)),single_eval_pos=len(x))\n",
       "    bounds = model.criterion.quantile(logits,center_prob=.682).squeeze(1)\n",
       "    return model.criterion.mean(logits).squeeze(1), bounds[:,0], bounds[:,1]\n",
       "\n",
       "def plot_w_conf_interval(ax_or_plt, x, m, lb, ub, color, label_prefix):\n",
       "    ax_or_plt.plot(x.squeeze(-1),m, color=color, label=label_prefix+' mean')\n",
       "    ax_or_plt.fill_between(x.squeeze(-1), lb, ub, alpha=.1, color=color, label=label_prefix+' conf. interval')\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "@torch.no_grad()\n",
       "def infer(table, choice):\n",
       "    vfunc = np.vectorize(lambda s: len(s))\n",
       "    non_empty_row_mask = (vfunc(table).sum(1) != 0)\n",
       "    table = table[non_empty_row_mask]\n",
       "\n",
       "    try:\n",
       "        table = table.astype(np.float32)\n",
       "    except ValueError:\n",
       "        return excuse, None\n",
       "    x = torch.tensor(table[:,0]).unsqueeze(1)\n",
       "    y = torch.tensor(table[:,1])\n",
       "    fig = plt.figure(figsize=(8,4),dpi=1000)\n",
       "\n",
       "    if len(x) > 4:\n",
       "        return excuse_max_examples, None\n",
       "    if (x<0.).any() or (x>1.).any() or (y<-1).any() or (y>1).any():\n",
       "        return excuse, None\n",
       "\n",
       "    plt.scatter(x,y, color='black', label='Examples in given dataset')\n",
       "\n",
       "\n",
       "    \n",
       "    test_xs = torch.linspace(0,1,100).unsqueeze(1)\n",
       "    \n",
       "    plot_w_conf_interval(plt, test_xs, *mean_and_bounds_for_gp(x,y,test_xs), 'green', 'GP')\n",
       "    plot_w_conf_interval(plt, test_xs, *mean_and_bounds_for_pnf(x,y,test_xs, choice), 'blue', 'PFN')\n",
       "    \n",
       "    plt.legend(ncol=2,bbox_to_anchor=[0.5,-.14],loc=\"upper center\")\n",
       "    plt.xlabel('x')\n",
       "    plt.ylabel('y')\n",
       "    plt.tight_layout()\n",
       "\n",
       "    \n",
       "    return 'There you go, your plot. 📈', plt.gcf()\n",
       "\n",
       "iface = gr.Interface(fn=infer,\n",
       "                     title='GP Posterior Approximation with Transformers',\n",
       "                     description='''This is a demo of PFNs as we describe them in our recent paper (https://openreview.net/forum?id=KSugKcbNf9).\n",
       "Lines represent means and shaded areas are the confidence interval (68.2% quantile). In green, we have the ground truth GP posterior and in blue we have our approximation.\n",
       "We provide three models that are architecturally the same, but with different training budgets.\n",
       "The GP (approximated) uses an RBF Kernel with a little noise (1e-4), 0 mean and a length scale of 0.1.\n",
       "                     ''',\n",
       "                     article=\"<p style='text-align: center'><a href='https://arxiv.org/abs/2112.10510'>Paper: Transformers Can Do Bayesian Inference</a></p>\",\n",
       "                     inputs=[\n",
       "                         gr.inputs.Dataframe(headers=[\"x\", \"y\"], datatype=[\"number\", \"number\"], type='numpy', default=[['.25','.1'],['.75','.4']], col_count=2, label='The data: you can change this and increase the number of data points using the `enter` key.'),\n",
       "                         gr.inputs.Radio(['160K','800K','4M'], type=\"value\", default='4M', label='Number of Sampled Datasets in Training (Training Costs), higher values yield better results')\n",
       "                     ], outputs=[\"text\",gr.outputs.Plot(type=\"matplotlib\")])\n",
       "iface.launch()\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"```python\\n{all_demo_links.iloc[62]['python_str']}\\n```\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
